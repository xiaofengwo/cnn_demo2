{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1. 图像预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip freeze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_image(img1,img2,str1,str2):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "    ax1.set_title(str1)\n",
    "    ax1.set_xticks([]), ax1.set_yticks([])\n",
    "    ax1.imshow(img1)\n",
    "\n",
    "    ax2.set_title(str2)\n",
    "    ax2.set_xticks([]), ax2.set_yticks([])\n",
    "    ax2.imshow(img2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Normalization and Scaling \n",
    "\n",
    "Reference:　\n",
    "+ https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/\n",
    "+ https://cs231n.github.io/neural-networks-2/\n",
    " \n",
    "For most image data, the pixel values are integers with values between 0 and 255.\n",
    "\n",
    "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n",
    "\n",
    "### 1. Normalization by Deviding all pixels by 255\n",
    "This is performed across all channels, regardless of the actual range of pixel values that are present in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'data/UCMerced_LandUse/Images/airplane/airplane20.tif'\n",
    "\n",
    "image = Image.open(image_path)\n",
    "pixels_orig = np.asarray(image)\n",
    "pixels = np.asarray(image)\n",
    "plt.imshow(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm pixel range is 0-255\n",
    "print('Original Data Type: %s' % pixels.dtype)\n",
    "print('Original Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "\n",
    "# normalize to the range 0-1\n",
    "# you code here\n",
    "pixels _______\n",
    "\n",
    "# confirm the normalization\n",
    "print('\\nNew Data Type: %s' % pixels.dtype)\n",
    "print('New Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_image(pixels_orig, pixels,\"Original\", \"Normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mean Subtraction\n",
    "This approach is called centering, as the distribution of the pixel values is centered on the value of zero.\n",
    "\n",
    "There are multiple ways that the mean can be calculated; for example:\n",
    "\n",
    "+ Per image.\n",
    "+ Per mini-batch of images (under stochastic gradient descent).\n",
    "+ Per training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean can be calculated for all pixels in the image, referred to as a global centering, or it can be calculated for each \n",
    "channel in the case of color images, referred to as local centering.\n",
    "\n",
    "+ Global Centering: Calculating and subtracting the mean pixel value across color channels.\n",
    "+ Local Centering: Calculating and subtracting the mean pixel value per color channel.\n",
    "\n",
    "In some cases, per-channel means are pre-calculated across an entire training dataset. In this case, the image means must be stored and used both during training and any inference with the trained models in the future. For example, the per-channel pixel means calculated for the ImageNet training dataset are as follows:\n",
    "\n",
    "ImageNet Training Dataset Means: [0.485, 0.456, 0.406]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Centering example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "pixels = np.asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate global mean\n",
    "mean = pixels.mean()\n",
    "\n",
    "print(\"Before centering:\")\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# global centering of pixels\n",
    "pixels = ___\n",
    "\n",
    "# confirm it had the desired effect\n",
    "mean = pixels.mean()\n",
    "print(\"\\nAfter centering:\")\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_image(pixels_orig,pixels,\"Original\", \"Global Centered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_image(pixels_orig,pixels.astype(np.uint8),\"Original\", \"Global Centered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Centering after Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "pixels_orig = np.asarray(image)\n",
    "pixels = np.asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "\n",
    "# Normalization\n",
    "pixels ____\n",
    "\n",
    "# calculate global mean\n",
    "mean = pixels.mean()\n",
    "print(\"Before centering:\")\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "\n",
    "# global centering of pixels\n",
    "pixels = _______\n",
    "\n",
    "# confirm it had the desired effect\n",
    "mean = pixels.mean()\n",
    "print(\"\\nAfter centering:\")\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_image(pixels_orig,pixels,\"Original\", \"Global Centered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Centering example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "pixels_orig = np.asarray(image)\n",
    "pixels = np.asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "\n",
    "# calculate per-channel means and standard deviations\n",
    "means = pixels.mean(axis=____, dtype='float64')\n",
    "\n",
    "print(\"Before centering:\")\n",
    "print('Means: %s' % means)\n",
    "print('Mins: %s, Maxs: %s' % (pixels.min(______), pixels.max(_____)))\n",
    "\n",
    "# per-channel centering of pixels\n",
    "pixels ______\n",
    "# confirm it had the desired effect\n",
    "\n",
    "means = pixels.mean(______, dtype='float64')\n",
    "\n",
    "print(\"\\nAfter centering:\")\n",
    "print('Means: %s' % means)\n",
    "print('Mins: %s, Maxs: %s' % (pixels.min(_____), pixels.max(_____)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_image(pixels_orig,pixels,\"Original\", \"Global Centered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the distribution of pixel values to be a standard Gaussian: that is both centering the pixel values on zero and normalizing the values by the standard deviation. The result is a standard Gaussian of pixel values with a mean of 0.0 and a standard deviation of 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Standardization\n",
    "The example below calculates the mean and standard deviation across all color channels in the loaded image, then uses these values to standardize the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image = Image.open(image_path)\n",
    "pixels_orig = np.asarray(image)\n",
    "\n",
    "pixels = np.asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "\n",
    "# calculate global mean and standard deviation\n",
    "mean, std = pixels.mean(), pixels.____\n",
    "\n",
    "print('Original Mean: %.3f, Standard Deviation: %.3f' % (mean, std))\n",
    "\n",
    "# global standardization of pixels\n",
    "pixels = ________\n",
    "\n",
    "# confirm it had the desired effect\n",
    "mean, std = pixels.mean(), pixels.std()\n",
    "print('New Mean: %.3f, Standard Deviation: %.3f' % (mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_image(pixels_orig,pixels,\"Original\", \"Global Standardized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image = Image.open(image_path)\n",
    "pixels = np.asarray(image)\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# calculate global mean and standard deviation\n",
    "\n",
    "means = pixels.mean(axis=(____), dtype='float64')\n",
    "stds = pixels.std(axis=(___), dtype='float64')\n",
    "\n",
    "print(\"Before centering:\")\n",
    "print('Means: %s' % means)\n",
    "print('Stds: %s' % stds)\n",
    "print('Mins: %s, Maxs: %s' % (pixels.min(axis=(___)), pixels.max(axis=(___))))\n",
    "\n",
    "# per-channel standardization of pixels\n",
    "pixels = (pixels - means) / ___ \n",
    "\n",
    "# confirm it had the desired effect\n",
    "means = pixels.mean(axis=(0,1), dtype='float64')\n",
    "stds = pixels.std(axis=(0,1), dtype='float64')\n",
    "print(\"\\nAfter centering:\")\n",
    "print('Means: %s' % means)\n",
    "print('Stds: %s' % stds)\n",
    "print('Mins: %s, Maxs: %s' % (pixels.min(axis=(___)), pixels.max(axis=(___))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_image(pixels_orig,pixels,\"Original\", \"Local Standardized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Common pitfall.\n",
    "\n",
    "An important point to make about the preprocessing is that any preprocessing statistics (e.g. the data mean) must only be computed on the training data, and then applied to the validation / test data. E.g. computing the mean and subtracting it from every image across the entire dataset and then splitting the data into train/val/test splits would be a mistake. Instead, the mean must be computed only over the training data and then subtracted equally from all splits (train/val/test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize, Center, and Standardize Image Pixels in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, the images would have to be scaled prior to the development of the model and stored in memory or on disk in the scaled format.\n",
    "\n",
    "An alternative approach is to scale the images using a preferred scaling technique just-in-time during the training or model evaluation process. Keras supports this type of data preparation for image data via the ImageDataGenerator class and API.\n",
    "\n",
    "Reference: https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create generator (1.0/255.0 = 0.003921568627451)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
    "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
    "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
    "\n",
    "batchX, batchy = train_iterator.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
    "\n",
    "# fit model with generator\n",
    "model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
